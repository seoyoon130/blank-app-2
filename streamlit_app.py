import os
import streamlit as st
import tempfile

from langchain.text_splitter import RecursiveCharacterTextSplitter  
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain.tools.retriever import create_retriever_tool
from langchain.prompts import ChatPromptTemplate
from langchain.agents import create_tool_calling_agent, AgentExecutor

# --------------------------------------------------------------------
# 1. Web Search Tool
# --------------------------------------------------------------------
def search_web():
    return TavilySearchResults(k=6, name="web_search")


# --------------------------------------------------------------------
# 2. PDF Tool
# --------------------------------------------------------------------
def load_pdf_files(uploaded_files):
    all_documents = []
    for uploaded_file in uploaded_files:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_file_path = tmp_file.name

        loader = PyPDFLoader(tmp_file_path)
        documents = loader.load()
        all_documents.extend(documents)

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    split_docs = text_splitter.split_documents(all_documents)

    vector = FAISS.from_documents(split_docs, OpenAIEmbeddings())
    retriever = vector.as_retriever(search_kwargs={"k": 5})

    retriever_tool = create_retriever_tool(
        retriever,
        name="pdf_search",
        description="This tool gives you direct access to the uploaded PDF documents. "
                    "Always use this tool first when the question might be answered from the PDFs."
    )
    return retriever_tool


# --------------------------------------------------------------------
# 3. Agent + Prompt êµ¬ì„±
# --------------------------------------------------------------------
def build_agent(tools):
    llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)

    prompt = ChatPromptTemplate.from_messages([
        ("system",
        "ë‹¹ì‹ ì€ ë˜‘ë˜‘í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ë‹¹ì‹ ì€ ì„¸ ê°€ì§€ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:\n"
        "- `csv_repl`: CSV ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ì „ìš© ë„êµ¬ì…ë‹ˆë‹¤. DataFrame `df`ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì´ì¬ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©°, ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ëª…ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n"
        "- `pdf_search`: PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ê²€ìƒ‰í•˜ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. ì§ˆë¬¸ì´ PDF ë‚´ìš©ê³¼ ê´€ë ¨ ìˆë‹¤ë©´ **ë°˜ë“œì‹œ ê°€ì¥ ë¨¼ì €** `pdf_search`ë¥¼ ì‚¬ìš©í•´ ë³´ì„¸ìš”. "
        "ë§Œì•½ ê´€ë ¨ëœ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ ê·¸ë•Œ ë‹¤ë¥¸ ë„êµ¬ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.\n"
        "- `web_search`: CSVë‚˜ PDFì™€ ë¬´ê´€í•œ ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸, ìµœì‹  ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ì¼ ê²½ìš° ì‚¬ìš©í•©ë‹ˆë‹¤.\n\n"
        "ë„êµ¬ ì„ íƒ ìš°ì„ ìˆœìœ„ ê·œì¹™:\n"
        "1. ì§ˆë¬¸ì´ PDF ë¬¸ì„œì™€ ê´€ë ¨ â†’ `pdf_search`ë¥¼ ê°€ì¥ ë¨¼ì € ì‹œë„. "
        "ë§Œì•½ ê´€ë ¨ ë‹µì„ ëª» ì°¾ìœ¼ë©´ ë‹¤ë¥¸ ë„êµ¬(`csv_repl` ë˜ëŠ” `web_search`)ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        "2. ì§ˆë¬¸ì— 'ë°ì´í„°'ë¼ëŠ” í‘œí˜„ì´ ìˆê±°ë‚˜, CSV ë¶„ì„/ì‹œê°í™”ê°€ í•„ìš”í•˜ë‹¤ë©´ `csv_repl`ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
        "3. ìœ„ ë‘ ê°€ì§€ê°€ ëª¨ë‘ ì•„ë‹ˆë©´ `web_search`ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.\n\n"
        "`csv_repl`ì„ ì‚¬ìš©í•  ë•ŒëŠ” ì‹¤í–‰í•œ íŒŒì´ì¬ ì½”ë“œì˜ ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì´ë‚˜ ê°€ê³µì€ í•˜ì§€ ë§ˆì„¸ìš”."),
        ("placeholder", "{chat_history}"),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}")
    ])

    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, return_intermediate_steps=True)

    return agent_executor


# --------------------------------------------------------------------
# 4. Agent ì‹¤í–‰ í•¨ìˆ˜
# --------------------------------------------------------------------
def ask_agent(agent_executor, question: str):
    result = agent_executor.invoke({"input": question})
    answer = result["output"]

    # intermediate_stepsì—ì„œ ë§ˆì§€ë§‰ë§Œ ê°€ì ¸ì˜¤ê¸°
    if result.get("intermediate_steps"):
        last_action, _ = result["intermediate_steps"][-1]
        answer += f"\n\nì¶œì²˜:\n- Tool: {last_action.tool}, Query: {last_action.tool_input}"

    return f"ë‹µë³€:\n{answer}"


# --------------------------------------------------------------------
# 5. Streamlit ë©”ì¸
# --------------------------------------------------------------------
def main():
    st.set_page_config(page_title="ë¶€ì‚°íŠ¸ë¦½ë´‡", layout="wide", page_icon=":ocean:")

    # ------------------------------
    # âœ… ë°°ê²½ ì´ë¯¸ì§€ + ê¸€ì”¨ ì˜¤ë²„ë ˆì´
    # ------------------------------
    st.markdown("""
        <style>
        .hero-container {
            position: relative;
            text-align: center;
        }
        .hero-image {
            width: 100%;
            border-radius: 10px;
        }
        .hero-text {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: white;
            font-size: 64px;
            font-weight: 900;
            text-shadow: 3px 3px 10px rgba(0,0,0,0.7);
        }
        </style>
        <div class="hero-container">
            <img src="data/busan.png" class="hero-image">
            <div class="hero-text">ë¶€ì‚°íŠ¸ë¦½ë´‡ ğŸŒŠ</div>
        </div>
    """, unsafe_allow_html=True)

    st.markdown('---')

    # ------------------------------
    # âœ… PDF ì—…ë¡œë“œë¥¼ ëŒ€í™”ì°½ ìœ„ë¡œ ì´ë™
    # ------------------------------
    openai_api = st.text_input("ğŸ”‘ OPENAI API í‚¤", type="password")
    tavily_api = st.text_input("ğŸ” TAVILY API í‚¤", type="password")
    pdf_docs = st.file_uploader("ğŸ“‚ PDF íŒŒì¼ ì—…ë¡œë“œ", accept_multiple_files=True)

    st.markdown("---")

    # ------------------------------
    # ì±—ë´‡ ë³¸ì²´
    # ------------------------------
    if openai_api and tavily_api:
        os.environ['OPENAI_API_KEY'] = openai_api
        os.environ['TAVILY_API_KEY'] = tavily_api

        tools = [search_web()]
        if pdf_docs:
            tools.append(load_pdf_files(pdf_docs))

        agent_executor = build_agent(tools)

        if "messages" not in st.session_state:
            st.session_state["messages"] = []

        user_input = st.chat_input("âœ‰ï¸ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”!")

        if user_input:
            response = ask_agent(agent_executor, user_input)
            st.session_state["messages"].append({"role": "user", "content": user_input})
            st.session_state["messages"].append({"role": "assistant", "content": response})

        for msg in st.session_state["messages"]:
            st.chat_message(msg["role"]).write(msg["content"])

    else:
        st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
